<!-- Powered by Product Genome™ Framework -->

# User DNA Validation Checklist

## Purpose

To validate that User DNA is evidence-based, specific, actionable, and grounded in real user research. This checklist ensures the User DNA document meets Product Genome quality standards and prevents "building for everyone" syndrome.

## How to Use This Checklist

- Review each item carefully
- Mark as ✅ Pass, ❌ Fail, or ⚠️ Needs Improvement
- Document specific findings for any failures or improvements needed
- A complete User DNA should have ALL items marked as Pass

---

## Section 1: User Segmentation Validation

### 1.1 Primary Segment Definition
- [ ] One primary user segment is clearly identified
- [ ] Primary segment has a descriptive name (not generic "users")
- [ ] Primary segment description is specific (who they are, what they do)
- [ ] Rationale for why this is PRIMARY segment is documented
- [ ] Population size estimate is provided
- [ ] Strategic importance of this segment is explained

**Finding:** _[Document specific issues or confirm pass]_

### 1.2 Segment Quality (Not Too Broad)
- [ ] Primary segment is specific enough to guide decisions
- [ ] Segment is NOT "everyone" or "all users"
- [ ] Segment definition allows saying "no" to non-segment users
- [ ] Different product decisions would be made for different segments

**Finding:** _[Document specific issues or confirm pass]_

### 1.3 Secondary Segments (if applicable)
- [ ] Secondary segments are identified (or N/A if only one segment)
- [ ] Each secondary segment has clear differences from primary
- [ ] Priority level is assigned to each segment
- [ ] Secondary segments don't dilute primary focus

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 2: Jobs-to-be-Done Validation

### 2.1 Primary JTBD Quality
- [ ] Primary JTBD follows format: "When [situation], I want to [motivation], so I can [outcome]"
- [ ] JTBD is specific to user context (not generic)
- [ ] JTBD focuses on progress user wants to make (not features they want)
- [ ] Functional job is clearly articulated
- [ ] Emotional job is identified
- [ ] Social job is identified (if applicable)

**Finding:** _[Document specific issues or confirm pass]_

### 2.2 JTBD Evidence
- [ ] JTBD is based on user research (interviews, observation)
- [ ] Research method used is documented
- [ ] JTBD is not assumed or invented in conference room
- [ ] Success criteria from user perspective are defined

**Finding:** _[Document specific issues or confirm pass]_

### 2.3 Secondary JTBDs (if applicable)
- [ ] Secondary JTBDs are documented (or N/A if only one job)
- [ ] Each JTBD has priority assigned
- [ ] JTBDs are distinct (not redundant)

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 3: User Context Validation

### 3.1 Usage Environment
- [ ] Physical environment is documented (where users use product)
- [ ] Environmental constraints are identified (lighting, noise, temperature, etc.)
- [ ] 3-5+ specific environmental factors are listed
- [ ] Environment understanding is based on observation (not assumption)

**Finding:** _[Document specific issues or confirm pass]_

### 3.2 Device & Connectivity Context
- [ ] Devices users actually use are documented (not what we wish they used)
- [ ] Connectivity constraints are identified
- [ ] Offline requirements are specified (if applicable)
- [ ] Device limitations are acknowledged

**Finding:** _[Document specific issues or confirm pass]_

### 3.3 Time Context
- [ ] Time pressures are documented
- [ ] Time constraints impact on product design is understood
- [ ] Usage frequency/duration is specified

**Finding:** _[Document specific issues or confirm pass]_

### 3.4 Cognitive Context
- [ ] User mental state during usage is understood
- [ ] Cognitive load factors are identified
- [ ] Stress levels and attention constraints are documented
- [ ] Multi-tasking or interruption patterns are noted

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 4: User Constraints Validation

### 4.1 Skill & Knowledge Constraints
- [ ] User skill levels are documented
- [ ] Knowledge gaps are identified
- [ ] Expertise variability is acknowledged
- [ ] Constraints inform design decisions (can't assume expert users)

**Finding:** _[Document specific issues or confirm pass]_

### 4.2 Time Constraints
- [ ] Specific time limitations are documented
- [ ] Time constraints are measurable (minutes, hours, etc.)
- [ ] Time pressure impact on UX is understood

**Finding:** _[Document specific issues or confirm pass]_

### 4.3 Physical & Environmental Constraints
- [ ] Physical limitations are documented (one-handed use, poor lighting, etc.)
- [ ] Environmental constraints inform design (screen glare, cold hands, etc.)
- [ ] Accessibility considerations are included

**Finding:** _[Document specific issues or confirm pass]_

### 4.4 Technology Constraints
- [ ] Actual device capabilities are documented (not idealized)
- [ ] Connectivity constraints are specified
- [ ] Storage/battery limitations are acknowledged
- [ ] Constraints drive technical decisions

**Finding:** _[Document specific issues or confirm pass]_

### 4.5 Organizational Constraints
- [ ] Organizational policies affecting usage are documented
- [ ] Budget or procurement constraints are noted
- [ ] IT or security constraints are identified

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 5: User Behavior Validation

### 5.1 Observed Behaviors
- [ ] Actual user behaviors are documented (not just stated preferences)
- [ ] Behaviors are based on observation/analytics (not guesses)
- [ ] 5+ specific behavioral patterns are listed
- [ ] Behaviors inform design decisions

**Finding:** _[Document specific issues or confirm pass]_

### 5.2 Current Workarounds
- [ ] Workarounds users currently employ are documented
- [ ] Workarounds reveal unmet needs
- [ ] 3-5+ specific workarounds are listed
- [ ] Product design addresses workaround pain

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 6: Evidence Sources Validation (CRITICAL)

### 6.1 Research Conducted
- [ ] Research methods table exists and is populated
- [ ] At least 2-3 different research methods were used
- [ ] Research includes dates and sample sizes
- [ ] Key findings from each research method are documented
- [ ] Research is recent (within last 6-12 months)

**Finding:** _[Document specific issues or confirm pass]_

### 6.2 Evidence Quality
- [ ] Evidence includes primary research (not just secondary)
- [ ] User interviews or observations were conducted
- [ ] Sample sizes are adequate for conclusions drawn
- [ ] Evidence is specific (not vague "users said they want...")

**Finding:** _[Document specific issues or confirm pass]_

### 6.3 Data Sources
- [ ] Quantitative data sources are documented
- [ ] Analytics or usage data informs understanding
- [ ] Support ticket or feedback data is analyzed
- [ ] Data connects to user needs and behaviors

**Finding:** _[Document specific issues or confirm pass]_

### 6.4 Ongoing Research Plan
- [ ] Plan for continuous user discovery exists
- [ ] Research frequency is specified
- [ ] Methods for ongoing learning are documented
- [ ] User DNA evolution is planned (not static)

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 7: User DNA Alignment

### 7.1 Purpose-User Alignment
- [ ] User segments align with Purpose DNA
- [ ] Users experience the problem stated in Purpose DNA
- [ ] User needs connect to solution vision

**Finding:** _[Document specific issues or confirm pass]_

### 7.2 User-Driven Design
- [ ] User constraints inform design decisions
- [ ] User context drives technical choices
- [ ] User behaviors shape feature priorities

**Finding:** _[Document specific issues or confirm pass]_

---

## Section 8: Document Completeness

### 8.1 Required Sections Present
- [ ] All required sections from template are present
- [ ] No sections contain placeholder text
- [ ] No sections are marked as "TBD" or "TODO"

**Finding:** _[Document specific issues or confirm pass]_

### 8.2 Validation Questions
- [ ] User DNA validation questions section exists
- [ ] 5-7 validation questions are provided
- [ ] Questions can be used to evaluate product decisions
- [ ] Questions prevent building for wrong users

**Finding:** _[Document specific issues or confirm pass]_

### 8.3 Change Log
- [ ] Change log exists
- [ ] Change log has at least initial entry
- [ ] Change log format is consistent

**Finding:** _[Document specific issues or confirm pass]_

---

## Overall Assessment

**Total Items:** _[Count total checklist items]_

**Passed:** _[Count items marked Pass]_

**Failed:** _[Count items marked Fail]_

**Needs Improvement:** _[Count items marked Needs Improvement]_

**Pass Rate:** _[Passed / Total]_ %

---

## Pass/Fail Criteria

- **PASS (Ready to Use):** 90%+ pass rate, zero critical failures
- **CONDITIONAL PASS (Usable with Improvements):** 75-89% pass rate, address improvements within 2 weeks
- **FAIL (Needs Major Revision):** <75% pass rate, significant gaps in core sections

**Overall Status:** _[PASS / CONDITIONAL PASS / FAIL]_

---

## Critical Failures (Automatic Fail)

If ANY of these are marked Fail, the User DNA cannot pass regardless of overall score:

- [ ] No primary user segment defined (or segment is "everyone")
- [ ] No evidence of user research conducted
- [ ] JTBD is invented/assumed (not research-based)
- [ ] No user constraints documented
- [ ] No research plan for ongoing discovery

**Critical Failures Detected:** _[Yes/No and list if yes]_

---

## Warning Signs (High Risk)

These don't cause automatic failure but indicate high risk of building wrong product:

- [ ] Research sample size < 10 users
- [ ] No field observation conducted (only surveys/interviews)
- [ ] Research is >12 months old
- [ ] Segments are based on demographics (not behaviors/needs/context)
- [ ] No secondary research methods used (single method only)

**Warning Signs Detected:** _[Count and list]_

---

## Recommendations

Based on checklist results, provide specific recommendations:

### High Priority Actions (Address Immediately)
1. _[Specific action based on failures]_
2. _[...]_

### Medium Priority Improvements (Address Soon)
1. _[Specific action based on needs improvement]_
2. _[...]_

### Ongoing Research Needs
1. _[Continuous discovery methods to implement]_
2. _[...]_

### Strengths to Maintain
1. _[What's working well]_
2. _[...]_

---

## Checklist Completion

**Reviewed By:** _[Name/Role]_

**Review Date:** _[Date]_

**Next Review Date:** _[Recommended: Every quarter or when new research conducted]_

**Status:** _[APPROVED / CONDITIONAL / REJECTED]_

**Notes:** _[Any additional context or observations]_
